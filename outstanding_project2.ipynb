{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the first Innings score in a ODI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Load the dataset from the csv file.\n",
    "2. Use “groupby” operation, to find the average number of runs, scored by each country,\n",
    "and represent it on a bar graph.\n",
    "3. Handle Missing values:\n",
    "a. If there are null values in continuous numerical column, replace the null values by\n",
    "the mean of that column\n",
    "b. If there are null values in ordinal numerical column, replace the null values by the\n",
    "mode of that column\n",
    "c. If there are null values in categorical column, replace the null values by the mode\n",
    "of that column\n",
    "d. If more than 50%the values in a column are null, then drop that entire column\n",
    "4. Remove the columns, that you think, do not contribute to the total score, in the first\n",
    "innings.\n",
    "5. Convert the categorical columns (if any), to numeric, using one hot encoding/ dummy\n",
    "encoding.\n",
    "6. Pick “total” column, as the target variable\n",
    "7. Select the relevant features.\n",
    "8. Perform train-test-split\n",
    "9. Perform Feature scaling\n",
    "10. Use\n",
    "a. Use Linear Regression\n",
    "b. Use Decision Tree Regression\n",
    "c. Use Random Forest Regression\n",
    "11. Evaluate the model\n",
    "12. Apply prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File odi.csv does not exist: 'odi.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a43ddfb5421e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'odi.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File odi.csv does not exist: 'odi.csv'"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv('odi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the data types of the columns\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use “groupby” operation, to find the average number of runs, scored by each country,and represent it on a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('bat_team').mean()['runs'].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Checking the null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**<br>\n",
    "This shows us their are no null values in each column.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the categorical columns (if any), to numeric, using one hot encoding/ dummy encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical features using OneHotEncoding method\n",
    "encoded_df = pd.get_dummies(data=dataset, columns=['bat_team','bowl_team','batsman','bowler','date','venue'])\n",
    "encoded_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy(y_test,y_pred,thresold):\n",
    "    right = 0\n",
    "\n",
    "    l = len(y_pred)\n",
    "    for i in range(0,l):\n",
    "        if(abs(y_pred[i]-y_test[i]) <= thresold):\n",
    "            right += 1\n",
    "    return ((right/l)*100)\n",
    "X = dataset.iloc[:,[7,8,9,12,13]].values\n",
    "y = dataset.iloc[:, 14].values\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train,y_train)\n",
    "\n",
    "# Testing the dataset on trained model\n",
    "y_pred = lin.predict(X_test)\n",
    "score = lin.score(X_test,y_test)*100\n",
    "print(\"R square value:\" , score)\n",
    "print(\"Custom accuracy:\" , custom_accuracy(y_test,y_pred,20))\n",
    "\n",
    "# Testing with a custom input\n",
    "import numpy as np\n",
    "new_prediction = lin.predict(sc.transform(np.array([[100,0,13,50,50]])))\n",
    "print(\"Prediction score:\" , new_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_accuracy(y_test,y_pred,thresold):\n",
    "    right = 0\n",
    "    l = len(y_pred)\n",
    "    for i in range(0,l):\n",
    "        if(abs(y_pred[i]-y_test[i]) <= thresold):\n",
    "            right += 1\n",
    "    return ((right/l)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestRegressor(n_estimators=100,max_features=None)\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "# Testing the dataset on trained model\n",
    "y_pred = reg.predict(X_test)\n",
    "score = reg.score(X_test,y_test)*100\n",
    "print(\"R square value:\" , score)\n",
    "print(\"Custom accuracy:\" , custom_accuracy(y_test,y_pred,20))\n",
    "\n",
    "# Testing with a custom input\n",
    "import numpy as np\n",
    "new_prediction = reg.predict(sc.transform(np.array([[100,0,13,50,50]])))\n",
    "print(\"Prediction score:\" , new_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression Model\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "D_T = tree.DecisionTreeRegressor(max_depth=8,random_state=42)\n",
    "D_T.fit(X_train, y_train)\n",
    "y_pred_dt = D_T.predict(X_test)\n",
    "print('The Score on the training set with a decision tree regressor is:',D_T.score(X_train,y_train))\n",
    "print('The Score on the test set with a decision tree regressor is:',D_T.score(X_test,y_test))\n",
    "\n",
    "# The Root mean squared error\n",
    "print(\"Mean squared error: %.2f\"% np.sqrt(mean_squared_error(y_test, y_pred_dt)))\n",
    "\n",
    "# The R^2 score \n",
    "print(\"The r2_score is: \", r2_score(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare all the models by checking their R2 score.<br>\n",
    "Condition: <br>\n",
    "* If R2 score is near to 1 -> Best model<br>\n",
    "* If R2 score is near to 0 -> Worst model<br>\n",
    "\n",
    "**Models**<br>\n",
    "Linear Regression :-     0.37<br>\n",
    "Decison tree Regressor:-      0.80<br>\n",
    "K Nearest Neighbours(KNN):- 0.73<br>\n",
    "Random Forest Regressor:- 0.90<br>\n",
    "\n",
    "So from observing the \"R2 score\" we conclude that *RANDOM FOREST REGRESSOR* is the best model for predicitng the price of the second hand car. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_score(bat_team='Chennai Super Kings', bowl_team='Mumbai Indians', overs=5.1, runs=50, wickets=0, runs_last_5=50, wickets_last_5=0):\n",
    "    temp_array = list()\n",
    "\n",
    "      # Batting Team\n",
    "    if bat_team == 'Chennai Super Kings':\n",
    "        temp_array = temp_array + [1,0,0,0,0,0,0,0]\n",
    "    elif bat_team == 'Delhi Daredevils':\n",
    "        temp_array = temp_array + [0,1,0,0,0,0,0,0]\n",
    "    elif bat_team == 'Kings XI Punjab':\n",
    "        temp_array = temp_array + [0,0,1,0,0,0,0,0]\n",
    "    elif bat_team == 'Kolkata Knight Riders':\n",
    "        temp_array = temp_array + [0,0,0,1,0,0,0,0]\n",
    "    elif bat_team == 'Mumbai Indians':\n",
    "        temp_array = temp_array + [0,0,0,0,1,0,0,0]\n",
    "    elif bat_team == 'Rajasthan Royals':\n",
    "        temp_array = temp_array + [0,0,0,0,0,1,0,0]\n",
    "    elif bat_team == 'Royal Challengers Bangalore':\n",
    "        temp_array = temp_array + [0,0,0,0,0,0,1,0]\n",
    "    elif bat_team == 'Sunrisers Hyderabad':\n",
    "        temp_array = temp_array + [0,0,0,0,0,0,0,1]\n",
    "\n",
    "      # Bowling Team\n",
    "    if bowl_team == 'Chennai Super Kings':\n",
    "        temp_array = temp_array + [1,0,0,0,0,0,0,0]\n",
    "    elif bowl_team == 'Delhi Daredevils':\n",
    "        temp_array = temp_array + [0,1,0,0,0,0,0,0]\n",
    "    elif bowl_team == 'Kings XI Punjab':\n",
    "        temp_array = temp_array + [0,0,1,0,0,0,0,0]\n",
    "    elif bowl_team == 'Kolkata Knight Riders':\n",
    "        temp_array = temp_array + [0,0,0,1,0,0,0,0]\n",
    "    elif bowl_team == 'Mumbai Indians':\n",
    "        temp_array = temp_array + [0,0,0,0,1,0,0,0]\n",
    "    elif bowl_team == 'Rajasthan Royals':\n",
    "        temp_array = temp_array + [0,0,0,0,0,1,0,0]\n",
    "    elif bowl_team == 'Royal Challengers Bangalore':\n",
    "        temp_array = temp_array + [0,0,0,0,0,0,1,0]\n",
    "    elif bowl_team == 'Sunrisers Hyderabad':\n",
    "        temp_array = temp_array + [0,0,0,0,0,0,0,1]\n",
    "\n",
    "      # Overs, Runs, Wickets, Runs_in_prev_5, Wickets_in_prev_5\n",
    "    temp_array = temp_array + [overs, runs, wickets, runs_last_5, wickets_last_5]\n",
    "\n",
    "      # Converting into numpy array\n",
    "    temp_array = np.array([temp_array])\n",
    "\n",
    "      # Prediction\n",
    "    return int(lin.predict(temp_array)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = predict_score(bat_team='England', bowl_team='Ireland', overs=0.1, runs=0, wickets=0, runs_last_5=0, wickets_last_5=0)\n",
    "print(\"The final predicted score (range): {} to {}\".format(final_score-10, final_score+5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
